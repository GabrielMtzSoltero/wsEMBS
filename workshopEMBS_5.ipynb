{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgR/M2fKSeFFnwkxQpo3KE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielMtzSoltero/wsEMBS/blob/main/workshopEMBS_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR6GBZ231HXj",
        "outputId": "ad685e5f-3ef1-489f-ff28-36c2482c12ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mysql-connector\n",
            "  Downloading mysql-connector-2.2.9.tar.gz (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mysql-connector\n",
            "  Building wheel for mysql-connector (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysql-connector: filename=mysql_connector-2.2.9-cp310-cp310-linux_x86_64.whl size=247952 sha256=3adc579f7b82de2557d2391abe99d19a387d7f3d95e26aa41597f91ea541b44b\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/48/9b/da67ff1a18fe8e9d428f9b1a177716d4a7d363d2bbe83bf6cf\n",
            "Successfully built mysql-connector\n",
            "Installing collected packages: mysql-connector\n",
            "Successfully installed mysql-connector-2.2.9\n"
          ]
        }
      ],
      "source": [
        "!pip install mysql-connector"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mysql.connector\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense,  Activation"
      ],
      "metadata": {
        "id": "zRAww5xr2rQ8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DB:\n",
        "    def __init__(self,_test=False):\n",
        "        conexionDB = mysql.connector.connect(\n",
        "        host=\"turtlechamber.com\",\n",
        "        user=\"embs\",\n",
        "        password=\"embs\",\n",
        "        database=\"breast_cancer\"\n",
        "        )\n",
        "        self.conexionDB=conexionDB\n",
        "        self.minRecord=1\n",
        "        self.maxRecord=500\n",
        "        if(_test):\n",
        "          self.minRecord=501\n",
        "          self.maxRecord=569\n",
        "        np.random.seed(1)\n",
        "        #self.getMinMaxRecords()\n",
        "    #para obtener el primer y ultimo registro\n",
        "    def getMinMaxRecords(self):\n",
        "        cursor =self.conexionDB.cursor()\n",
        "        query= \"SELECT MIN(bc_id),MAX(bc_id) FROM breast_cancer\"\n",
        "        cursor.execute(query)\n",
        "        resultado=cursor.fetchone()\n",
        "        print(resultado)\n",
        "        self.minRecord=resultado[0]\n",
        "        self.maxRecord=resultado[1]\n",
        "\n",
        "    def read_records_at(self, ids):\n",
        "        cursor =self.conexionDB.cursor()\n",
        "        valores=\",\".join(map(str, ids))\n",
        "        query= \"SELECT * FROM breast_cancer WHERE bc_id in ({})\".format(valores)\n",
        "        cursor.execute(query)\n",
        "        result=cursor.fetchall()\n",
        "        X=[]\n",
        "        y=[]\n",
        "        for row in result:\n",
        "            X.append(row[2:])\n",
        "            y.append([row[1]])\n",
        "        X=np.array(X,dtype='float32')\n",
        "        y=np.array(y,dtype='float32')\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "HRrHHZxjBoc4"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, db, batch_size=32):\n",
        "    self.db = db\n",
        "    self.idx = np.arange(self.db.minRecord,self.db.maxRecord+1)\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor((self.db.maxRecord-self.db.minRecord) / self.batch_size))\n",
        "\n",
        "  # Generate a batch of (X, y)\n",
        "  def __getitem__(self, index):\n",
        "    idxs = np.random.randint(self.db.minRecord,self.db.maxRecord+1,size=(self.batch_size))\n",
        "    return self.db.read_records_at(idxs)"
      ],
      "metadata": {
        "id": "JTx8cSIOCgu3"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calis = DataGenerator(DB(), 2)\n",
        "calis.__getitem__(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rXy10L4L3gB",
        "outputId": "0d21006c-ff0f-4cb3-bb8e-b383b8bab0d5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1.303e+01, 1.842e+01, 8.261e+01, 5.238e+02, 8.983e-02, 3.766e-02,\n",
              "         2.562e-02, 2.923e-02, 1.467e-01, 5.863e-02, 1.839e-01, 2.342e+00,\n",
              "         1.170e+00, 1.416e+01, 4.352e-03, 4.899e-03, 1.343e-02, 1.164e-02,\n",
              "         2.671e-02, 1.777e-03, 1.330e+01, 2.281e+01, 8.446e+01, 5.459e+02,\n",
              "         9.701e-02, 4.619e-02, 4.833e-02, 5.013e-02, 1.987e-01, 6.169e-02],\n",
              "        [1.403e+01, 2.125e+01, 8.979e+01, 6.034e+02, 9.070e-02, 6.945e-02,\n",
              "         1.462e-02, 1.896e-02, 1.517e-01, 5.835e-02, 2.589e-01, 1.503e+00,\n",
              "         1.667e+00, 2.207e+01, 7.389e-03, 1.383e-02, 7.302e-03, 1.004e-02,\n",
              "         1.263e-02, 2.925e-03, 1.533e+01, 3.028e+01, 9.827e+01, 7.155e+02,\n",
              "         1.287e-01, 1.513e-01, 6.231e-02, 7.963e-02, 2.226e-01, 7.617e-02]],\n",
              "       dtype=float32),\n",
              " array([[1.],\n",
              "        [1.]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.src.metrics import binary_accuracy\n",
        "model = keras.models.Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=30))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=[\"accuracy\",])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "df = DataGenerator(DB(), 256)\n",
        "dftest = DataGenerator(DB(_test=True))\n",
        "\n",
        "model.fit(df,epochs=80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_46T9_X6C7cr",
        "outputId": "0f17d807-43b7-4b10-e5ba-2d00b795d3ed"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_71 (Dense)            (None, 64)                1984      \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4097 (16.00 KB)\n",
            "Trainable params: 4097 (16.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "1/1 [==============================] - 1s 1s/step - loss: 99.0217 - accuracy: 0.6184 - binary_accuracy: 0.6184\n",
            "Epoch 2/80\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 83.6239 - accuracy: 0.6089 - binary_accuracy: 0.6089\n",
            "Epoch 3/80\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 62.4906 - accuracy: 0.6094 - binary_accuracy: 0.6094\n",
            "Epoch 4/80\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 49.5597 - accuracy: 0.5775 - binary_accuracy: 0.5775\n",
            "Epoch 5/80\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 27.1895 - accuracy: 0.6350 - binary_accuracy: 0.6350\n",
            "Epoch 6/80\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 10.9853 - accuracy: 0.6650 - binary_accuracy: 0.6650\n",
            "Epoch 7/80\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 2.7250 - accuracy: 0.3520 - binary_accuracy: 0.3520\n",
            "Epoch 8/80\n",
            "1/1 [==============================] - 0s 242ms/step - loss: 9.7675 - accuracy: 0.3737 - binary_accuracy: 0.3737\n",
            "Epoch 9/80\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 14.5658 - accuracy: 0.3776 - binary_accuracy: 0.3776\n",
            "Epoch 10/80\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 16.5191 - accuracy: 0.3959 - binary_accuracy: 0.3959\n",
            "Epoch 11/80\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 17.3020 - accuracy: 0.3614 - binary_accuracy: 0.3614\n",
            "Epoch 12/80\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 15.7334 - accuracy: 0.3960 - binary_accuracy: 0.3960\n",
            "Epoch 13/80\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 13.7471 - accuracy: 0.4032 - binary_accuracy: 0.4032\n",
            "Epoch 14/80\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 11.1277 - accuracy: 0.4194 - binary_accuracy: 0.4194\n",
            "Epoch 15/80\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 8.4851 - accuracy: 0.3650 - binary_accuracy: 0.3650\n",
            "Epoch 16/80\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 3.9384 - accuracy: 0.3897 - binary_accuracy: 0.3897\n",
            "Epoch 17/80\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 1.5795 - accuracy: 0.6103 - binary_accuracy: 0.6103\n",
            "Epoch 18/80\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 4.1015 - accuracy: 0.6995 - binary_accuracy: 0.6995\n",
            "Epoch 19/80\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 7.7886 - accuracy: 0.6029 - binary_accuracy: 0.6029\n",
            "Epoch 20/80\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 9.6205 - accuracy: 0.6111 - binary_accuracy: 0.6111\n",
            "Epoch 21/80\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 6.3461 - accuracy: 0.6733 - binary_accuracy: 0.6733\n",
            "Epoch 22/80\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 4.2253 - accuracy: 0.7143 - binary_accuracy: 0.7143\n",
            "Epoch 23/80\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 1.7300 - accuracy: 0.7951 - binary_accuracy: 0.7951\n",
            "Epoch 24/80\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 1.2705 - accuracy: 0.6588 - binary_accuracy: 0.6588\n",
            "Epoch 25/80\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 2.6775 - accuracy: 0.3719 - binary_accuracy: 0.3719\n",
            "Epoch 26/80\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 3.4915 - accuracy: 0.4208 - binary_accuracy: 0.4208\n",
            "Epoch 27/80\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 4.4084 - accuracy: 0.3575 - binary_accuracy: 0.3575\n",
            "Epoch 28/80\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 3.2472 - accuracy: 0.4229 - binary_accuracy: 0.4229\n",
            "Epoch 29/80\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 2.3941 - accuracy: 0.4257 - binary_accuracy: 0.4257\n",
            "Epoch 30/80\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 1.5957 - accuracy: 0.6465 - binary_accuracy: 0.6465\n",
            "Epoch 31/80\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 1.5152 - accuracy: 0.7778 - binary_accuracy: 0.7778\n",
            "Epoch 32/80\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 1.7476 - accuracy: 0.8060 - binary_accuracy: 0.8060\n",
            "Epoch 33/80\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 2.5686 - accuracy: 0.7971 - binary_accuracy: 0.7971\n",
            "Epoch 34/80\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 2.1484 - accuracy: 0.8186 - binary_accuracy: 0.8186\n",
            "Epoch 35/80\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 1.5166 - accuracy: 0.8317 - binary_accuracy: 0.8317\n",
            "Epoch 36/80\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 1.5464 - accuracy: 0.8333 - binary_accuracy: 0.8333\n",
            "Epoch 37/80\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 1.5169 - accuracy: 0.7659 - binary_accuracy: 0.7659\n",
            "Epoch 38/80\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 1.2580 - accuracy: 0.7704 - binary_accuracy: 0.7704\n",
            "Epoch 39/80\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 1.3843 - accuracy: 0.6300 - binary_accuracy: 0.6300\n",
            "Epoch 40/80\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 1.8177 - accuracy: 0.6114 - binary_accuracy: 0.6114\n",
            "Epoch 41/80\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 1.3065 - accuracy: 0.6181 - binary_accuracy: 0.6181\n",
            "Epoch 42/80\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 1.3481 - accuracy: 0.6881 - binary_accuracy: 0.6881\n",
            "Epoch 43/80\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 1.0908 - accuracy: 0.7259 - binary_accuracy: 0.7259\n",
            "Epoch 44/80\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 1.0791 - accuracy: 0.7673 - binary_accuracy: 0.7673\n",
            "Epoch 45/80\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.7508 - accuracy: 0.8109 - binary_accuracy: 0.8109\n",
            "Epoch 46/80\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.9294 - accuracy: 0.8522 - binary_accuracy: 0.8522\n",
            "Epoch 47/80\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 1.2500 - accuracy: 0.8477 - binary_accuracy: 0.8477\n",
            "Epoch 48/80\n",
            "1/1 [==============================] - 0s 242ms/step - loss: 0.9220 - accuracy: 0.8505 - binary_accuracy: 0.8505\n",
            "Epoch 49/80\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 1.5004 - accuracy: 0.8520 - binary_accuracy: 0.8520\n",
            "Epoch 50/80\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 1.3239 - accuracy: 0.8528 - binary_accuracy: 0.8528\n",
            "Epoch 51/80\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 0.6239 - accuracy: 0.8691 - binary_accuracy: 0.8691\n",
            "Epoch 52/80\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.9794 - accuracy: 0.8390 - binary_accuracy: 0.8390\n",
            "Epoch 53/80\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 1.0982 - accuracy: 0.7549 - binary_accuracy: 0.7549\n",
            "Epoch 54/80\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.9684 - accuracy: 0.7537 - binary_accuracy: 0.7537\n",
            "Epoch 55/80\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.9529 - accuracy: 0.7083 - binary_accuracy: 0.7083\n",
            "Epoch 56/80\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 1.0105 - accuracy: 0.7586 - binary_accuracy: 0.7586\n",
            "Epoch 57/80\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.8199 - accuracy: 0.8384 - binary_accuracy: 0.8384\n",
            "Epoch 58/80\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.6687 - accuracy: 0.8621 - binary_accuracy: 0.8621\n",
            "Epoch 59/80\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.5274 - accuracy: 0.8738 - binary_accuracy: 0.8738\n",
            "Epoch 60/80\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.7653 - accuracy: 0.8693 - binary_accuracy: 0.8693\n",
            "Epoch 61/80\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.9606 - accuracy: 0.8650 - binary_accuracy: 0.8650\n",
            "Epoch 62/80\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.8122 - accuracy: 0.8683 - binary_accuracy: 0.8683\n",
            "Epoch 63/80\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.5850 - accuracy: 0.8895 - binary_accuracy: 0.8895\n",
            "Epoch 64/80\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.4598 - accuracy: 0.8841 - binary_accuracy: 0.8841\n",
            "Epoch 65/80\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.6121 - accuracy: 0.8041 - binary_accuracy: 0.8041\n",
            "Epoch 66/80\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.6400 - accuracy: 0.8050 - binary_accuracy: 0.8050\n",
            "Epoch 67/80\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.5956 - accuracy: 0.8227 - binary_accuracy: 0.8227\n",
            "Epoch 68/80\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.5074 - accuracy: 0.8374 - binary_accuracy: 0.8374\n",
            "Epoch 69/80\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.5897 - accuracy: 0.8310 - binary_accuracy: 0.8310\n",
            "Epoch 70/80\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.4819 - accuracy: 0.8614 - binary_accuracy: 0.8614\n",
            "Epoch 71/80\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.4266 - accuracy: 0.9036 - binary_accuracy: 0.9036\n",
            "Epoch 72/80\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.3476 - accuracy: 0.9091 - binary_accuracy: 0.9091\n",
            "Epoch 73/80\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.4576 - accuracy: 0.8783 - binary_accuracy: 0.8783\n",
            "Epoch 74/80\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.3938 - accuracy: 0.8775 - binary_accuracy: 0.8775\n",
            "Epoch 75/80\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.2487 - accuracy: 0.9014 - binary_accuracy: 0.9014\n",
            "Epoch 76/80\n",
            "1/1 [==============================] - 0s 344ms/step - loss: 0.3742 - accuracy: 0.8687 - binary_accuracy: 0.8687\n",
            "Epoch 77/80\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.2952 - accuracy: 0.8927 - binary_accuracy: 0.8927\n",
            "Epoch 78/80\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.2414 - accuracy: 0.9235 - binary_accuracy: 0.9235\n",
            "Epoch 79/80\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.3833 - accuracy: 0.8756 - binary_accuracy: 0.8756\n",
            "Epoch 80/80\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.2160 - accuracy: 0.9387 - binary_accuracy: 0.9387\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ec7e0960ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict([[ 11.2, 29.37, 70.67, 386, 0.07449, 0.03558, 0, 0, 0.106, 0.05502, 0.3141, 3.896, 2.041, 22.81, 0.007594, 0.008878, 0, 0, 0.01989, 0.001773, 11.92, 38.3, 75.19, 439.6, 0.09267, 0.05494, 0, 0, 0.1566, 0.05905]])\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pqDI08FFbXW",
        "outputId": "b4bce4be-92be-417b-a958-441298970487"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.97001666]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(dftest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xCtgIDKKp0r",
        "outputId": "c36f3665-a72c-4b48-ce82-45fe8944c517"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 192ms/step - loss: 0.2797 - accuracy: 0.9200 - binary_accuracy: 0.9200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.27974313497543335, 0.9200000166893005, 0.9200000166893005]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}